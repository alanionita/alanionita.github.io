---
title: Strava to FOSS analysis and visualisation
url: 2025.03.19.strava-to-foss
desc: ''
updated: 19/03/2025
created: 19/03/2025
tags: ['foss', 'python', 'GeoPandas', 'geospatial']
---

# Strava to FOSS analysis and visualisation

[image]

Having used Strava for years I've always been suprised that no one else has made a better alternative. 

The UI has been frozen in time, and most of the *good* features are paywalled.

I for one refuse to pay for Strava to analyse my data. In my opinion a better way to sell the subscription is to be so good, so useful, that I'm beging Strava to take my money.

That being said, Strava is good at tracking. Whilst I haven't done any thorough testing, Strava has worked well for me in terms of tracking accuracy. 

I also enjoy the interval voice notifications and the multi-sport tracking, cycling expecially.

The challenges also, get me outside in mechanical way that I appreciate, whilst cringing that I'm encouradged to go outside by the prospect of money of very expensive kit.

Anyway, where do we go from here...

Until I roll my sleeves and warm up my LLMs to build my own tracking app, I will continue to use Strava. 

But I'm planning to own more of my data, and interogate it locally. And this was the inception moement for the 'Strava to FOSS' project. 

## The Project

Core features:
- Download activity data from Strava
- Convert data to geospacial data
- Use GeoPandas to explore data
- Use OSMnx to enrich the data with OpenStreetMap nodes
- Use OSMnx and Leaflet to generate custom maps

The project is currently just a series of notebooks on Github, but overtime will be a proper service.

https://github.com/alanionita/strava-to-foss-notebooks-python

## Talking to Strava

The `strava_data.ipynb` notebook show an example of dealing with the Strava OAuth flow.

I won't go into detail, since the notebook is easy to follow. Do note that the example just gets the first 10 activities.

Once you reached the end of that process you will have an `activities.json`.

## The data 

For the sake of our task we need to get the route of the activity, and one way to do this is to use the `.map.summary_polyline`

```json
[
	{
		"map": {
        	    	"id": "a13798432720",
            		"summary_polyline": "",
            		"resource_state": 2
		},
	}
]
```

Unclear why, but some activities don't have this entry, whilst other valid entries contain a string. 

Also unclear is whether this value will contain elevation data, we have `_high` and `_low` elev values within the actitvity. A good mystery to uncover in a future post and feature.

> Note that most of the supporting code from this point forward is about the `osm.ipynb` notebook.

## Geospatial primer

### Geometry

Quick intro to geospacial data is that most things relate to Lines, Polylines, and Polygons.

We normally work with these basic geometric shapes using a low level lib called Shapely.

Incidently whenever we use a geospacial framework, like GeoPanda, they in turn will use Shapely under the hood. 

Normally you just get the data in a nice format, but when you're unlocking existing data you will need to implement Shapely for data conversions.

### Coordinates

Another important concept with geospacial data is the use of coordinates: latitude, longitude. 

You'll see below that in order to make our lives easier we convert original PolyLine data to a geospatial list of coordinates. 

I can't stress to you how useful this can be for future analysis.

Take a regular 20km run as geospacial lists: we end up with ~300 coordinate points, we can then compare distances between these, track time across each coordinate point and more.

### Formats and GeoInfra

Geospacial data use a JSON flavour called `.geojson`. You'll see below that there's a big fuss about saving our converted data to `.geojson` so that we do the format conversion in one step and end up with a portable reusable geospacial file for later geospacial focused tasks.

We can go further and instead of saving to a file, we can save the data to a database like PostGIS. Unfortunetly not covered here, but stay tuned.

## Geospatial data

Back to our Strava data. 

1. Get the coordinate points

This `summary_polyline` string is a Google Maps encoded Polyline, a propriatary format. 

We will need to decode this using Shapely, because we want the coordinate points.

2. Convert them to the right coordinate reference system

We need to understand what cartographic system did they originally use in their encoding. I'll spare you the head scratching, Google Maps uses Mercator system or EPSG:3857.

Best way to imagine the CRS is to imagine yourself in space, floating about. Now imagine that your friend is also there with you, floating around like a maniac. Great! Now I ask that both you and your friend look down at the Eifel tower, manifique!

You and your friend will be looking at the same coordinate (lat,lng), but you each have a different angle to that coordinate. As such you each have your or CRS.

We do this crs conversion via GeoPandas.

3. Working with GeoPandas

When we use GeoPandas we need to also deal with how it expects coordinates. By default GeoPandas expects a crs called WGS84 or EPSG:4326.

When we load the data from the original Polyline conversion we need to load it as WGS84 and then change the crs to Mercator.

But we're not done quite yet. You see that WGS84 crs is very important for geographic operations inside GeoPandas. Mapping, distance, comparisons are all done in the WGS84 crs.

Before we start doing these geographic operations we need to make sure that we convert back from Mercator to WGS84.

What happens if we load the data as WSG84?

I encouradge you to try it and see, once you set up the mapping of the data. 

If you want to take my word for it.

WIP
